{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import MSMatch as mm\n",
    "\n",
    "cfg = mm.get_default_cfg()\n",
    "mm.set_seeds(cfg.seed)\n",
    "logger_level = \"INFO\"\n",
    "logger = mm.get_logger(cfg.save_name, cfg.save_path, logger_level)\n",
    "tb_log = mm.TensorBoardLog(cfg.save_path, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9533969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Dataset\n",
    "train_dset = mm.SSL_Dataset(\n",
    "    name=cfg.dataset, train=True, data_dir=None, seed=cfg.seed,\n",
    ")\n",
    "lb_dset, ulb_dset = train_dset.get_ssl_dset(cfg.num_labels)\n",
    "\n",
    "cfg.num_classes = train_dset.num_classes\n",
    "cfg.num_channels = train_dset.num_channels\n",
    "\n",
    "_eval_dset = mm.SSL_Dataset(\n",
    "    name=cfg.dataset, train=False, data_dir=None, seed=cfg.seed,\n",
    ")\n",
    "eval_dset = _eval_dset.get_dset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b55c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_builder = mm.get_net_builder(\n",
    "    cfg.net,\n",
    "    pretrained=cfg.pretrained,\n",
    "    in_channels=cfg.num_channels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee210e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mm.FixMatch(\n",
    "        net_builder,\n",
    "        cfg.num_classes,\n",
    "        cfg.num_channels,\n",
    "        cfg.ema_m,\n",
    "        T=0.5,\n",
    "        p_cutoff=cfg.p_cutoff,\n",
    "        lambda_u=cfg.ulb_loss_ratio,\n",
    "        hard_label=True,\n",
    "        num_eval_iter=cfg.num_eval_iter,\n",
    "        tb_log=tb_log,\n",
    "        logger=logger,\n",
    "    )\n",
    "logger.info(f\"Number of Trainable Params: {sum(p.numel() for p in model.train_model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1180564",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.epoch = 10\n",
    "cfg.num_train_iter = cfg.epoch * cfg.num_eval_iter * 32 // cfg.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = mm.get_optimizer(\n",
    "    model.train_model, cfg.opt, cfg.lr, cfg.momentum, cfg.weight_decay\n",
    ")\n",
    "scheduler = mm.get_cosine_schedule_with_warmup(\n",
    "    optimizer, cfg.num_train_iter, num_warmup_steps=cfg.num_train_iter * 0\n",
    ")\n",
    "model.set_optimizer(optimizer, scheduler)\n",
    "if torch.cuda.is_available():\n",
    "    cfg.gpu = 0\n",
    "    torch.cuda.set_device(cfg.gpu)\n",
    "    model.train_model = model.train_model.cuda(cfg.gpu)\n",
    "    model.eval_model = model.eval_model.cuda(cfg.gpu)\n",
    "\n",
    "logger.info(f\"model_arch: {model}\")\n",
    "logger.info(f\"Arguments: {cfg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e096708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct data loader\n",
    "loader_dict = {}\n",
    "dset_dict = {\"train_lb\": lb_dset, \"train_ulb\": ulb_dset, \"eval\": eval_dset}\n",
    "\n",
    "loader_dict[\"train_lb\"] = get_data_loader(\n",
    "    dset_dict[\"train_lb\"],\n",
    "    cfg.batch_size,\n",
    "    data_sampler=\"RandomSampler\",\n",
    "    num_iters=cfg.num_train_iter,\n",
    "    num_workers=1,\n",
    "    distributed=False,\n",
    ")\n",
    "\n",
    "loader_dict[\"train_ulb\"] = get_data_loader(\n",
    "    dset_dict[\"train_ulb\"],\n",
    "    cfg.batch_size * cfg.uratio,\n",
    "    data_sampler=\"RandomSampler\",\n",
    "    num_iters=cfg.num_train_iter,\n",
    "    num_workers=4,\n",
    "    distributed=False,\n",
    ")\n",
    "\n",
    "loader_dict[\"eval\"] = get_data_loader(\n",
    "    dset_dict[\"eval\"], cfg.eval_batch_size, num_workers=1\n",
    ")\n",
    "\n",
    "## set DataLoader on FixMatch\n",
    "model.set_data_loader(loader_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = model.train\n",
    "print(cfg)\n",
    "\n",
    "for epoch in range(cfg.epoch):\n",
    "    print(epoch)\n",
    "    trainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"latest_model.pth\", cfg.save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torchmatch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ddf264bb344b85a2f0436b8e15459b084b5ee9678e571d1be85bf8d829f31722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
